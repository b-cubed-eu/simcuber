[{"path":"https://b-cubed-eu.github.io/gcube/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behaviour participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behaviour may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant (http://contributor-covenant.org), version 1.0.0, available http://contributor-covenant.org/version/1/0/0/","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"CONTRIBUTING","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. E.g. edit roxygen2 comment .R file R/, .Rd file man/.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"","what":"Prerequisites","title":"CONTRIBUTING","text":"make substantial pull request, always file issue make sure someone team agrees ’s problem. ’ve found bug, create associated issue illustrate bug minimal reproducible example.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"","what":"Pull request process","title":"CONTRIBUTING","text":"recommend create Git branch pull request (PR). Look GitHub Actions build status making changes. README contain badges continuous integration services used package. require tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"CONTRIBUTING","text":"Please note project released Contributor Code Conduct. contributing project agree abide terms.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"prefer-to-email","dir":"","previous_headings":"","what":"Prefer to Email?","title":"CONTRIBUTING","text":"Email person listed maintainer DESCRIPTION file repo. Though note private discussions email don’t help others - course email totally warranted ’s sensitive problem kind.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/CONTRIBUTING.html","id":"thanks-for-contributing","dir":"","previous_headings":"","what":"Thanks for contributing!","title":"CONTRIBUTING","text":"contributing guide adapted tidyverse contributing guide available https://raw.githubusercontent.com/r-lib/usethis/master/inst/templates/tidy-contributing.md","code":""},{"path":"https://b-cubed-eu.github.io/gcube/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 Research Institute Nature Forest (INBO) Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/articles/detection-process.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"2. Simulating the detection process","text":"functions set single polygon input enough go workflow using default arguments. user can change arguments allow flexibility. input, create polygon simulate occurrences. polygon looks like .  can example sample randomly within polygon 6 time points use random walk time initial average number occurrences equal 100 (see vignette(\"occurrence-process\")). spatial distribution occurrences time point","code":"polygon <- st_polygon(list(cbind(c(500, 1000, 1000, 600, 200, 100, 500),                                  c(200, 100, 700, 1000, 900, 500, 200)))) ggplot() +   geom_sf(data = polygon) +   theme_minimal() occurrences_df <- simulate_occurrences(   plgn = polygon,   initial_average_abundance = 100,   n_time_points = 6,   temporal_function = simulate_random_walk,   sd_step = 1,   spatial_autocorr = \"random\",   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_sf(data = polygon) +   geom_sf(data = occurrences_df) +   facet_wrap(~time_point, nrow = 2) +   ggtitle(\"Distribution of occurrences for each time point\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/detection-process.html","id":"detect-occurrences","dir":"Articles","previous_headings":"","what":"Detect occurrences","title":"2. Simulating the detection process","text":"occurrences, occurrences generally observed. detection occurrences depends detection probability species sampling bias (includes sampling bias effort). process can simulated using sample_observations() function. observation detection probability value (=observations) bias weight depending spatial distribution. combination detection probability bias weight results sampling probability used decide whether occurrence detected using (rbinom(1, 1, sampling_probability)). bias 3 options: \"no_bias\", \"polygon\" \"manual\". \"no_bias\", detection probability value decide whether occurrence observed . \"polygon\", bias weights depend location inside outside given polygon certain bias strength. can visualise using helper function apply_polygon_sampling_bias(). Lets say road across polygon. Define road width. Create road points. Create road-like polygon within given polygon. Plot result.  can say occurrences road 2x larger probability detected. see occurrences road twice bias weights occurrences.  \"manual\", bias weights depend location inside grid cells given grid cell value. can visualise using helper function apply_manual_sampling_bias(). Lets create grid give random bias weights cell. Plot grid.  use helper function. use time point 1. indeed see higher bias weights occurrences higher values grid cells.","code":"?sample_observations ?apply_polygon_sampling_bias road_width <- 50 road_points <- rbind(c(100, 500), c(1000, 500)) road_polygon <- st_linestring(road_points) %>%   st_buffer(road_width) %>%   st_intersection(polygon) %>%   st_polygon() %>%   st_sfc() %>%   st_as_sf() %>%   rename(geometry = x) ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   theme_minimal() occurrence_bias_df1 <- apply_polygon_sampling_bias(   occurrences_df,   bias_area = road_polygon,   bias_strength = 2) ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   geom_sf(data = occurrence_bias_df1,           aes(colour = factor(round(bias_weight, 3)))) +   facet_wrap(~time_point, nrow = 2) +   labs(title = \"Distribution of occurrences for each time point\",        colour = \"bias_weight\") +   theme_minimal() ?apply_manual_sampling_bias grid <- st_make_grid(     polygon,     n = c(10, 10),     square = TRUE) %>%   st_sf() set.seed(123) grid$bias_weight <- runif(nrow(grid), min = 0, max = 1) ggplot() +   geom_sf(data = polygon) +   geom_sf(data = grid, alpha = 0) +   geom_sf_text(data = grid, aes(label = round(bias_weight, 2))) +   theme_minimal() occurrence_bias_df2 <- apply_manual_sampling_bias(   occurrences_df %>% dplyr::filter(time_point == 1),   bias_weights = grid) ggplot() +   geom_sf(data = polygon) +   geom_sf(data = grid, alpha = 0) +   geom_sf(data = occurrence_bias_df2,           aes(colour = bias_weight)) +   geom_sf_text(data = grid, aes(label = round(bias_weight, 2))) +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/detection-process.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"2. Simulating the detection process","text":"Now know helper functions work, can simulate detection process using sample_observations() function. can example state species 0.9 detection probability time say small chance detect road. see lot occurrences detected due high detection probability, case road detected.","code":"detections_df_raw <- sample_observations(   occurrences_df,   detection_probability = 0.9,   sampling_bias = \"polygon\",   bias_area = road_polygon,   bias_strength = 0.1,   seed = 123) ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   geom_sf(data = detections_df_raw,           aes(colour = sampling_status)) +   scale_colour_manual(values = c(\"blue\", \"red\")) +   facet_wrap(~time_point, nrow = 2) +   labs(title = \"Distribution of occurrences for each time point\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/detection-process.html","id":"adding-coordinate-uncertainty","dir":"Articles","previous_headings":"","what":"Adding coordinate uncertainty","title":"2. Simulating the detection process","text":"mimic real life data collection, can finally add coordinate uncertainty observations. keep detected occurrences previous example. add coordinate uncertainty observations using add_coordinate_uncertainty() function. can add value observations vector single value observation. Lets add 25 meters uncertainty observation. Created sf object uncertainty circles visualise .","code":"detections_df <- detections_df_raw %>%   dplyr::filter(sampling_status == \"detected\") ?add_coordinate_uncertainty observations_df <- add_coordinate_uncertainty(   observations = detections_df,   coords_uncertainty_meters = 25) buffered_observations <- st_buffer(   observations_df,   observations_df$coordinateUncertaintyInMeters)  ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   geom_sf(data = buffered_observations,           fill = alpha(\"firebrick\", 0.3)) +   geom_sf(data = observations_df, colour = \"firebrick\", size = 0.8) +   facet_wrap(~time_point, nrow = 2) +   labs(title = \"Distribution of observations for each time point\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/grid-designation-process.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"3. Specifying the grid designation process","text":"functions set single polygon input enough go workflow using default arguments. user can change arguments allow flexibility. input, create polygon simulate occurrences. polygon looks like .  Also consider road across polygon. result looks like .  can example sample randomly within polygon 6 time points use random walk time initial average number occurrences equal 100 (see vignette(\"occurrence-process\")). spatial distribution occurrences time point  detect occurrences using 0.9 detection probability bias 0.1 detect occurrences road (see vignette(\"detection-process\")). spatial distribution occurrences time point  keep detected occurrences add 25 meters uncertainty observation (see vignette(\"detection-process\")). final observations uncertainty circles look like .","code":"polygon <- st_polygon(list(cbind(c(500, 1000, 1000, 600, 200, 100, 500),                                  c(200, 100, 700, 1000, 900, 500, 200)))) ggplot() +   geom_sf(data = polygon) +   theme_minimal() # Define the road width road_width <- 50  # Create road points road_points <- rbind(c(100, 500), c(1000, 500))  # Create road-like polygon within the given polygon road_polygon <- st_linestring(road_points) %>%   st_buffer(road_width) %>%   st_intersection(polygon) %>%   st_polygon() %>%   st_sfc() %>%   st_as_sf() %>%   rename(geometry = x) ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   theme_minimal() occurrences_df <- simulate_occurrences(   plgn = polygon,   initial_average_abundance = 100,   n_time_points = 6,   temporal_function = simulate_random_walk,   sd_step = 1,   spatial_autocorr = \"random\",   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_sf(data = polygon) +   geom_sf(data = occurrences_df) +   facet_wrap(~time_point, nrow = 2) +   ggtitle(\"Distribution of occurrences for each time point\") +   theme_minimal() detections_df_raw <- sample_observations(   occurrences_df,   detection_probability = 0.9,   sampling_bias = \"polygon\",   bias_area = road_polygon,   bias_strength = 0.1,   seed = 123) ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   geom_sf(data = detections_df_raw,           aes(colour = sampling_status)) +   scale_colour_manual(values = c(\"blue\", \"red\")) +   facet_wrap(~time_point, nrow = 2) +   labs(title = \"Distribution of occurrences for each time point\") +   theme_minimal() # Keep detected occurrences detections_df <- detections_df_raw %>%   dplyr::filter(sampling_status == \"detected\")  # Add 25 m coordinate uncertainty observations_df <- add_coordinate_uncertainty(   observations = detections_df,   coords_uncertainty_meters = 25) # Create sf object with uncertainty circles buffered_observations <- st_buffer(   observations_df,   observations_df$coordinateUncertaintyInMeters)  # Visualise ggplot() +   geom_sf(data = polygon, fill = \"lightgreen\") +   geom_sf(data = road_polygon) +   geom_sf(data = buffered_observations,           fill = alpha(\"firebrick\", 0.3)) +   geom_sf(data = observations_df, colour = \"firebrick\", size = 0.8) +   facet_wrap(~time_point, nrow = 2) +   labs(title = \"Distribution of observations for each time point\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/grid-designation-process.html","id":"grid-designation","dir":"Articles","previous_headings":"","what":"Grid designation","title":"3. Specifying the grid designation process","text":"Now can make data cube observations taking account uncertainty. can create grid using grid_designation() function. also need grid. observation designated grid cell. grid looks like .  grid designation take coordinate uncertainty account? default \"uniform\" randomisation random point within uncertainty circle taken location observation. point designated overlapping grid cell. Another option \"normal\" point sampled bivariate Normal distribution means equal observation point variance equal (-coordinateUncertaintyInMeters^2) / (2 * log(1 - p_norm)) p_norm % possible samples Normal distribution fall within uncertainty circle. can visualised using helper functions. Lets create single random point 25 meter coordinate uncertainty. sample 1000 times using uniform normal randomisation look difference methods. take 1000 samples uniform randomisation. take 1000 samples normal randomisation case uniform randomisation, see samples everywhere evenly spread within uncertainty circle.  case normal randomisation, see samples outside uncertainty circle. 0.05 (=1 - p_norm) %. also see samples closer central point.  coordinate uncertainty provided, original observation point used grid designation.","code":"?grid_designation cube_grid <- st_make_grid(   st_buffer(polygon, 25),   n = c(20, 20),   square = TRUE) %>%   st_sf() ggplot() +   geom_sf(data = polygon) +   geom_sf(data = cube_grid, alpha = 0) +   theme_minimal() ?sample_from_uniform_circle ?sample_from_binormal_circle # Create point and add coordinate uncertainty point_df <- tibble(   x = 200,   y = 500,   time_point = 1,   coordinateUncertaintyInMeters = 25) %>%   st_as_sf(coords = c(\"x\", \"y\"))  # Number of simulations n_sim <- 1000 list_samples_uniform <- vector(\"list\", length = n_sim) for (i in seq_len(n_sim)) {   sampled_point_uniform <- sample_from_uniform_circle(point_df)   sampled_point_uniform$sim <- i   list_samples_uniform[[i]] <- sampled_point_uniform } samples_uniform_df <- do.call(rbind.data.frame, list_samples_uniform) list_samples_normal <- vector(\"list\", length = n_sim) for (i in seq_len(n_sim)) {   sampled_point_normal <- sample_from_binormal_circle(point_df, p_norm = 0.95)   sampled_point_normal$sim <- i   list_samples_normal[[i]] <- sampled_point_normal } samples_normal_df <- do.call(rbind.data.frame, list_samples_normal) # Get coordinates coordinates_uniform_df <- data.frame(st_coordinates(samples_uniform_df)) coordinates_normal_df <- data.frame(st_coordinates(samples_normal_df)) coordinates_point_df <- data.frame(st_coordinates(point_df))  # Create figures for both randomisations scatter_uniform <- ggplot() +   geom_point(data = coordinates_uniform_df,              aes(x = X, y = Y),              colour = \"cornflowerblue\") +   geom_segment(data = coordinates_point_df,                aes(x = X, xend = X + 25,                    y = Y, yend = Y),                linewidth = 1.5, colour = \"darkgreen\") +   geom_label(aes(y = 503, x = 212.5, label = \"25 m\"), colour = \"black\",             size = 5) +   geom_point(data = coordinates_point_df,              aes(x = X, y = Y),              color = \"firebrick\", size = 2) +   coord_fixed() +   theme_minimal()  scatter_normal <- ggplot() +   geom_point(data = coordinates_normal_df,              aes(x = X, y = Y),              colour = \"cornflowerblue\") +   geom_segment(data = coordinates_point_df,                aes(x = X, xend = X + 25,                    y = Y, yend = Y),                linewidth = 1.5, colour = \"darkgreen\") +   geom_label(aes(y = 503, x = 212.5, label = \"25 m\"), colour = \"black\",              size = 5) +   stat_ellipse(data = coordinates_normal_df, aes(x = X, y = Y),                level = 0.975, linewidth = 1, color = \"firebrick\") +   geom_point(data = coordinates_point_df,              aes(x = X, y = Y),              color = \"firebrick\", size = 2) +   coord_fixed() +   theme_minimal() ggExtra::ggMarginal(scatter_uniform, type = \"histogram\") ggExtra::ggMarginal(scatter_normal, type = \"histogram\")"},{"path":"https://b-cubed-eu.github.io/gcube/articles/grid-designation-process.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"3. Specifying the grid designation process","text":"Now know use randomisation grid_designation(). default use uniform randomisation. create occurrence cube time point 1. grid cell (column id) time point (column time_point), get number observations (column n, sampled within uncertainty circle) minimal coordinate uncertainty (column min_coord_uncertainty). latter 25 grid cell since observation coordinate uncertainty. Get sampled points within uncertainty circle setting aggregate = FALSE. Lets visualise samples taken time point 1.  Visualise minimal coordinate uncertainty time points 1 2.","code":"occurrence_cube_df <- grid_designation(   observations_df,   cube_grid,   seed = 123) head(occurrence_cube_df %>% st_drop_geometry()) #> # A tibble: 6 × 4 #>   time_point id        n min_coord_uncertainty #>        <int> <chr> <int>                 <dbl> #> 1          1 106       1                    25 #> 2          1 107       1                    25 #> 3          1 109       1                    25 #> 4          1 112       1                    25 #> 5          1 113       1                    25 #> 6          1 116       1                    25 sampled_points <- grid_designation(   observations_df,   cube_grid,   seed = 123,   aggregate = FALSE) ggplot() +   geom_sf(data = polygon) +   geom_sf(data = occurrence_cube_df %>% dplyr::filter(time_point == 1),           alpha = 0) +   geom_sf_text(data = occurrence_cube_df %>% dplyr::filter(time_point == 1),                aes(label = n)) +   geom_sf(data = buffered_observations %>% dplyr::filter(time_point == 1),           fill = alpha(\"firebrick\", 0.3)) +   geom_sf(data = sampled_points %>% dplyr::filter(time_point == 1),           colour = \"blue\") +   geom_sf(data = observations_df %>% dplyr::filter(time_point == 1),           colour = \"firebrick\") +   theme_minimal() ggplot() +   geom_sf(data = polygon) +   geom_sf(data = occurrence_cube_df %>% dplyr::filter(time_point %in% 1:2),           aes(fill = min_coord_uncertainty), alpha = 0.5) +   geom_sf_text(data = occurrence_cube_df %>% dplyr::filter(time_point %in% 1:2),                aes(label = n)) +   facet_wrap(~time_point) +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/occurrence-process.html","id":"input","dir":"Articles","previous_headings":"","what":"Input","title":"1. Simulating the occurrence process","text":"functions set single polygon input enough go workflow using default arguments. user can change arguments allow flexibility. vignette demonstrate different options. input, create polygon want simulate occurrences. polygon looks like .","code":"polygon <- st_polygon(list(cbind(c(500, 1000, 1000, 600, 200, 100, 500),                                  c(200, 100, 700, 1000, 900, 500, 200)))) ggplot() +   geom_sf(data = polygon) +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/occurrence-process.html","id":"simulate-occurrences","dir":"Articles","previous_headings":"","what":"Simulate occurrences","title":"1. Simulating the occurrence process","text":"generate occurrence points within polygon using simulate_occurrences() function. Default arguments ensure sf object POLYGON geometry sufficient simulate occurrences. options user defined arguments demonstrated next subsections.","code":"?simulate_occurrences"},{"path":"https://b-cubed-eu.github.io/gcube/articles/occurrence-process.html","id":"changing-number-of-occurrences-over-time","dir":"Articles","previous_headings":"Simulate occurrences","what":"Changing number of occurrences over time","title":"1. Simulating the occurrence process","text":"Say want 100 occurrences plot 10 years. can change trend number occurrences time. visualise helper functions used simulate_occurrences(). number occurrences always drawn Poisson distribution. Option 1 specify temporal function, draw Poisson distribution time point average (lambda parameter) initial_average_occurrences. plot simulated number occurrences time. see average close 100 time expected. Using different seed result different numbers average (close ) 100 time.  Option 2 can specify function , e.g. internal function simulate_random_walk() random walk time. random walk mathematical concept step determined randomly. sd_step parameter refers standard deviation random steps (drawn Normal distribution). higher value leading larger steps potentially greater variability path random walk. plot simulated number occurrences time follow random walk. Using different seed result different random pattern.  Option 3 can specify function determines average trend number occurrences time. provide example linear trend. try linear trend slope equal 1. plot simulated number occurrences time. see average slope indeed close 1. Using different seed result different numbers average slope (close ) 1.","code":"?simulate_timeseries n_occurrences_indep <- simulate_timeseries(   initial_average_occurrences = 100,   n_time_points = 10,   temporal_function = NA,   seed = 123) tibble(   n_occurrences = n_occurrences_indep,   time_point = seq_along(n_occurrences_indep)   ) %>%   ggplot(aes(x = time_point, y = n_occurrences)) +     geom_point() +     geom_smooth(method = \"lm\", formula = \"y ~ x\", se = FALSE) +     theme_minimal() n_occurrences_walk <- simulate_timeseries(   initial_average_occurrences = 100,   n_time_points = 10,   temporal_function = simulate_random_walk,   sd_step = 1,   seed = 123) tibble(   n_occurrences = n_occurrences_walk,   time_point = seq_along(n_occurrences_walk)   ) %>%   ggplot(aes(x = time_point, y = n_occurrences)) +     geom_point() +     theme_minimal() my_own_linear_function <- function(     initial_average_occurrences = initial_average_occurrences,     n_time_points = n_time_points,     coef) {   # Calculate new average abundances over time   time <- seq_len(n_time_points) - 1   lambdas <- initial_average_occurrences + (coef * time)    # Identify where the lambda values become 0 or lower   zero_or_lower_index <- which(lambdas <= 0)    # If any lambda becomes 0 or lower, set all subsequent lambdas to 0   if (length(zero_or_lower_index) > 0) {     zero_or_lower_indices <- zero_or_lower_index[1]:n_time_points     lambdas[zero_or_lower_indices] <- 0   }    # Return average abundances   return(lambdas) } n_occurrences_linear <- simulate_timeseries(   initial_average_occurrences = 100,   n_time_points = 10,   temporal_function = my_own_linear_function,   coef = 1,   seed = 123) tibble(   n_occurrences = n_occurrences_linear,   time_point = seq_along(n_occurrences_linear)   ) %>%   ggplot(aes(x = time_point, y = n_occurrences)) +     geom_point() +     geom_smooth(method = \"lm\", formula = \"y ~ x\", se = FALSE) +     theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/occurrence-process.html","id":"changing-the-degree-of-spatial-clustering","dir":"Articles","previous_headings":"Simulate occurrences","what":"Changing the degree of spatial clustering","title":"1. Simulating the occurrence process","text":"can also choose amount spatial clustering. visualise helper functions used simulate_occurrences(). Option 1 defaults random clustered patterns. Let’s look default clustering. see values high sampling probability randomly distributed.  Option 2 Let’s look default clustering (spatial_pattern = 10, see ). see values high sampling probability clustered together.  Option 3 can also change clustering . larger number spatial_pattern means broader size clusters area. Let’s look low value clustering. see values high sampling probability multiple, smaller clusters.  Let’s look high value clustering. see values high sampling probability fewer, larger clusters.  patterns generated used sampling using different helper function. example sample 500 occurrences last raster, see sampling according expected pattern.","code":"?create_spatial_pattern rs_pattern_random <- create_spatial_pattern(   polygon = polygon,   resolution = 10,   spatial_pattern = \"random\",   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_spatraster(data = rs_pattern_random) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal() rs_pattern_clustered <- create_spatial_pattern(   polygon = polygon,   resolution = 10,   spatial_pattern = \"clustered\",   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_spatraster(data = rs_pattern_clustered) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal() rs_pattern_clustered2 <- create_spatial_pattern(   polygon = polygon,   resolution = 10,   spatial_pattern = 5,   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_spatraster(data = rs_pattern_clustered2) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal() rs_pattern_clustered3 <- create_spatial_pattern(   polygon = polygon,   resolution = 10,   spatial_pattern = 100,   seed = 123) #> [using unconditional Gaussian simulation] ggplot() +   geom_spatraster(data = rs_pattern_clustered3) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal() ?sample_occurrences_from_raster pts_occ_clustered3 <- sample_occurrences_from_raster(   rs = rs_pattern_clustered3,   ts = 500,   seed = 123)  ggplot() +   geom_spatraster(data = rs_pattern_clustered3) +   geom_sf(data = pts_occ_clustered3) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/articles/occurrence-process.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"1. Simulating the occurrence process","text":"Now know helper functions work, can generate occurrence points within polygon using simulate_occurrences() function. can example sample randomly within polygon 6 time points use random walk time initial average number occurrences equal 100. number occurrences time point.  spatial distribution occurrences time point.","code":"occurrences_df <- simulate_occurrences(   plgn = polygon,   initial_average_abundance = 100,   n_time_points = 6,   temporal_function = simulate_random_walk,   sd_step = 1,   spatial_autocorr = \"random\",   seed = 123) #> [using unconditional Gaussian simulation] occurrences_df %>%   st_drop_geometry() %>%   count(time_point) %>%   ggplot(aes(x =  time_point, y = n)) +     geom_point() +     theme_minimal() ggplot() +   geom_sf(data = polygon) +   geom_sf(data = occurrences_df) +   facet_wrap(~time_point, nrow = 2) +   ggtitle(\"Distribution of occurrences for each time point\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ward Langeraert. Author, maintainer.            Research Institute Nature Forest (INBO) Wissam Barhdadi. Contributor. Dimitri Brosens. Contributor. Rocìo Cortès. Contributor. Peter Desmet. Contributor. Michele Di Musciano. Contributor. Chandra Earl. Contributor. Sanne Govaert. Contributor. Pieter Huybrechts. Contributor. Matilde Martini. Contributor. Arthur Rodrigues. Contributor. Toon Van Daele. Contributor. Annegreet Veeken. Contributor. Mukhtar Muhammed Yahaya. Contributor. Research Institute Nature Forest (INBO). Copyright holder. European Union's Horizon Europe Research Innovation Programme (ID 101059592). Funder.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Langeraert, Ward (2024) gcube: Simulating Biodiversity Data Cubes. Version 0.0.1. https://b-cubed-eu.github.io/gcube/","code":"@Manual{,   title = {gcube: Simulating Biodiversity Data Cubes. Version 0.0.1},   author = {Ward Langeraert},   year = {2024},   url = {https://b-cubed-eu.github.io/gcube/},   abstract = {Simulation framework for biodiversity data cubes.},   keywords = {simulation; data cubes; B-Cubed; biodiversity; Monte-Carlo}, }"},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"gcube-","dir":"","previous_headings":"","what":"Simulating Biodiversity Data Cubes","title":"Simulating Biodiversity Data Cubes","text":"goal gcube provide simulation framework biodiversity data cubes using R programming language. can start simulating multiple species distributed landscape temporal scope. second phase, simulation variety observation processes effort can generate actual occurrence datasets. Based (simulated) spatial uncertainty, occurrences can designated grid form data cube. Simulation studies offer numerous benefits due ability mimic real-world scenarios controlled customizable environments. Ecosystems biodiversity data complex involve multitude interacting factors. Simulations allow researchers model understand complexity ecological systems varying parameters spatial /temporal clustering, species prevalence, etc.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Simulating Biodiversity Data Cubes","text":"can install development version GitHub :","code":"# install.packages(\"remotes\") remotes::install_github(\"b-cubed-eu/gcube\")"},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Simulating Biodiversity Data Cubes","text":"basic example shows workflow simulating biodiversity data cube. divided three steps processes: Occurrence process Detection process Grid designation process functions set single polygon input enough go workflow using default arguments. user can change arguments allow flexibility. create random polygon input.","code":"# Load packages library(gcube)  library(sf)      # working with spatial objects library(dplyr)   # data wrangling library(ggplot2) # visualisation with ggplot # Create a polygon to simulate occurrences polygon <- st_polygon(list(cbind(c(5,10,8,2,3,5), c(2,1,7,9,5,2))))  # Visualise ggplot() +    geom_sf(data = polygon) +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"occurrence-process","dir":"","previous_headings":"Example","what":"Occurrence process","title":"Simulating Biodiversity Data Cubes","text":"generate occurrence points within polygon using simulate_occurrences() function. “real” occurrences species, whether observed . simulate_occurrences() function, user can specify different levels spatial clustering, can define trend change species time.","code":"# Simulate occurrences within polygon occurrences_df <- simulate_occurrences(   plgn = polygon,   seed = 123) #> [using unconditional Gaussian simulation] # Visualise ggplot() +    geom_sf(data = polygon) +   geom_sf(data = occurrences_df) +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"detection-process","dir":"","previous_headings":"Example","what":"Detection process","title":"Simulating Biodiversity Data Cubes","text":"step define sampling process, based detection probability species sampling bias. done using sample_observations() function. default sampling bias \"no_bias\", bias can also inserted using polygon grid.  select detected occurrences add uncertainty observations. can done using add_coordinate_uncertainty() function.","code":"# Detect occurrences detections_df_raw <- sample_observations(   occurrences = occurrences_df,   detection_probability = 0.5,   seed = 123)  # Visualise ggplot() +    geom_sf(data = polygon) +   geom_sf(data = detections_df_raw,           aes(colour = sampling_status)) +   theme_minimal() # Select detected occurrences only detections_df <- detections_df_raw %>%   dplyr::filter(sampling_status == \"detected\")  # Add coordinate uncertainty set.seed(123) coord_uncertainty_vec <- rgamma(nrow(detections_df), shape = 2, rate = 6) observations_df <- add_coordinate_uncertainty(   observations = detections_df,   coords_uncertainty_meters = coord_uncertainty_vec)  # Created and sf object with uncertainty circles to visualise buffered_observations <- st_buffer(   observations_df,   observations_df$coordinateUncertaintyInMeters)  # Visualise ggplot() +    geom_sf(data = polygon) +   geom_sf(data = buffered_observations,           fill = alpha(\"firebrick\", 0.3)) +   geom_sf(data = observations_df, colour = \"firebrick\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/index.html","id":"grid-designation-process","dir":"","previous_headings":"Example","what":"Grid designation process","title":"Simulating Biodiversity Data Cubes","text":"Finally, observations designated grid create occurrence cube. create grid spatial extend using sf::st_make_grid(). create occurrence cube, grid_designation() randomly take point within uncertainty circle around observations. points can extracted setting argument aggregate = FALSE.  output gives number observations per grid cell minimal coordinate uncertainty per grid cell.","code":"# Define a grid over spatial extend grid_df <- st_make_grid(     buffered_observations,     square = TRUE,     cellsize = c(1.2, 1.2)   ) %>%   st_sf() %>%   mutate(intersect = as.vector(st_intersects(geometry, polygon,                                              sparse = F))) %>%   dplyr::filter(intersect == TRUE) %>%   dplyr::select(-\"intersect\") # Create occurrence cube occurrence_cube_df <- grid_designation(   observations = observations_df,   grid = grid_df,   seed = 123)  # Get sampled points within uncertainty circle sampled_points <- grid_designation(   observations = observations_df,   grid = grid_df,   aggregate = FALSE,   seed = 123)  # Visualise grid designation ggplot() +   geom_sf(data = occurrence_cube_df, linewidth = 1) +   geom_sf_text(data = occurrence_cube_df, aes(label = n)) +   geom_sf(data = buffered_observations,           fill = alpha(\"firebrick\", 0.3)) +   geom_sf(data = sampled_points, colour = \"blue\") +   geom_sf(data = observations_df, colour = \"firebrick\") +   labs(x = \"\", y = \"\", fill = \"n\") +   theme_minimal() # Visualise minimal coordinate uncertainty ggplot() +   geom_sf(data = occurrence_cube_df, aes(fill = min_coord_uncertainty),           alpha = 0.5, linewidth = 1) +   geom_sf_text(data = occurrence_cube_df, aes(label = n)) +   scale_fill_continuous(type = \"viridis\") +   labs(x = \"\", y = \"\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/reference/add_coordinate_uncertainty.html","id":null,"dir":"Reference","previous_headings":"","what":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","title":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","text":"Adds column observations sf object coordinate uncertainty meters.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/add_coordinate_uncertainty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","text":"","code":"add_coordinate_uncertainty(observations, coords_uncertainty_meters = 25)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/add_coordinate_uncertainty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","text":"observations sf object POINT geometry. coords_uncertainty_meters numeric value vector numeric values indicating coordinate uncertainty associated observations.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/add_coordinate_uncertainty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","text":"sf object POINT geometry additional column coordinateUncertaintyInMeters.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/add_coordinate_uncertainty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add coordinate uncertainty to observations — add_coordinate_uncertainty","text":"","code":"library(sf) #> Linking to GEOS 3.10.2, GDAL 3.4.1, PROJ 8.2.1; sf_use_s2() is TRUE library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  set.seed(123)  # Create four random points n_points <- 4 xlim <- c(3841000, 3842000) ylim <- c(3110000, 3112000) observations_sf <- data.frame(   lat = runif(n_points, ylim[1], ylim[2]),     long = runif(n_points, xlim[1], xlim[2])) %>%     st_as_sf(coords = c(\"long\", \"lat\"), crs = 3035)   # provide a fixed uncertainty for all points  add_coordinate_uncertainty(    observations_sf,    coords_uncertainty_meters = 1000    ) #> Simple feature collection with 4 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 3841046 ymin: 3110575 xmax: 3841940 ymax: 3111766 #> Projected CRS: ETRS89-extended / LAEA Europe #>                  geometry coordinateUncertaintyInMeters #> 1 POINT (3841940 3110575)                          1000 #> 2 POINT (3841046 3111577)                          1000 #> 3 POINT (3841528 3110818)                          1000 #> 4 POINT (3841892 3111766)                          1000  # add variability in uncertainty. For example, using gamma distribution add_coordinate_uncertainty(   observations_sf,   coords_uncertainty_meters = rgamma(n_points, shape = 5, rate = 0.1) ) #> Simple feature collection with 4 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 3841046 ymin: 3110575 xmax: 3841940 ymax: 3111766 #> Projected CRS: ETRS89-extended / LAEA Europe #>                  geometry coordinateUncertaintyInMeters #> 1 POINT (3841940 3110575)                      47.78440 #> 2 POINT (3841046 3111577)                      88.73564 #> 3 POINT (3841528 3110818)                      55.30862 #> 4 POINT (3841892 3111766)                      22.16495"},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_manual_sampling_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a sampling bias via a grid — apply_manual_sampling_bias","title":"Generate a sampling bias via a grid — apply_manual_sampling_bias","text":"function adds sampling bias weight column containing sample probability based bias weights within cell given grid layer.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_manual_sampling_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a sampling bias via a grid — apply_manual_sampling_bias","text":"","code":"apply_manual_sampling_bias(occurrences_sf, bias_weights)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_manual_sampling_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a sampling bias via a grid — apply_manual_sampling_bias","text":"occurrences_sf sf object POINT geometry. bias_weights raster layer (sf object POLYGON geometry). raster bias weights applied sampling occurrences. sf object contain bias_weight geometry column. Higher weights indicate higher probability sampling. Weights must numeric values 0 1 positive integers rescaled values 0 1.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_manual_sampling_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a sampling bias via a grid — apply_manual_sampling_bias","text":"sf object POINT geometry bias_weight column containing sampling probability based sampling bias.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_manual_sampling_bias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a sampling bias via a grid — apply_manual_sampling_bias","text":"","code":"# Load packages library(sf) library(dplyr) library(ggplot2)  # Set seed for reproducibility set.seed(123)  # Simulate some occurrence data with coordinates and time points num_points <- 10 occurrences <- data.frame(   lon = runif(num_points, min = -180, max = 180),   lat = runif(num_points, min = -90, max = 90),   time_point = 0 )  # Convert the occurrence data to an sf object occurrences_sf <- st_as_sf(occurrences, coords = c(\"lon\", \"lat\"))  # Create raster grid grid <- st_make_grid(occurrences_sf) %>%   st_sf()  # Bias weights between 0 and 1 grid1 <- grid %>%   mutate(bias_weight = runif(nrow(grid), min = 0, max = 1))  apply_manual_sampling_bias(occurrences_sf, grid1) #> Simple feature collection with 10 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #>    time_point bias_weight                   geometry #> 5           0  0.14711365 POINT (158.5682 -71.47356) #> 8           0  0.14711365 POINT (141.2709 -82.42928) #> 7           0  0.13880606 POINT (10.11798 -45.70421) #> 9           0  0.20653139 POINT (18.51661 -30.97427) #> 2           0  0.79434232 POINT (103.7898 -8.399852) #> 4           0  0.11113542  POINT (137.8863 13.07401) #> 3           0  0.10286464 POINT (-32.76831 31.96271) #> 6           0  0.93529980 POINT (-163.5997 71.96849) #> 1           0  0.06072057    POINT (-76.47209 82.23) #> 10          0  0.72059627  POINT (-15.6187 81.81066)  # Bias weights larger than 1 grid2 <- grid %>%   mutate(bias_weight = rpois(nrow(grid), 5))  occurrence_bias_sf <- apply_manual_sampling_bias(occurrences_sf, grid2) occurrence_bias_sf #> Simple feature collection with 10 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #>    time_point bias_weight                   geometry #> 5           0         0.6 POINT (158.5682 -71.47356) #> 8           0         0.6 POINT (141.2709 -82.42928) #> 7           0         0.3 POINT (10.11798 -45.70421) #> 9           0         0.4 POINT (18.51661 -30.97427) #> 2           0         0.4 POINT (103.7898 -8.399852) #> 4           0         0.5  POINT (137.8863 13.07401) #> 3           0         0.5 POINT (-32.76831 31.96271) #> 6           0         0.5 POINT (-163.5997 71.96849) #> 1           0         0.3    POINT (-76.47209 82.23) #> 10          0         0.2  POINT (-15.6187 81.81066)  # Visualise where the bias is ggplot() +  geom_sf(data = grid2) +  geom_sf_text(data = grid2, aes(label = bias_weight)) +  geom_sf(data = occurrence_bias_sf, aes(colour = bias_weight)) +  scale_color_gradient(trans = \"reverse\")"},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_polygon_sampling_bias.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","title":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","text":"function adds sampling bias weight column containing sample probability based bias strength within given polygon.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_polygon_sampling_bias.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","text":"","code":"apply_polygon_sampling_bias(occurrences_sf, bias_area, bias_strength = 1)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_polygon_sampling_bias.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","text":"occurrences_sf sf object POINT geometry. bias_area sf object POLYGON geometry. area sampling biased. bias_strength positive numeric value. strength bias applied biased area (multiplier). 1, area oversampled. 1, area undersampled. example, value 50 result 50 times samples within bias_area outside. Conversely, value 0.5 result half less samples within bias_area outside.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_polygon_sampling_bias.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","text":"sf object POINT geometry bias_weight column containing sampling probability based sampling bias.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/apply_polygon_sampling_bias.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a sampling bias via a polygon — apply_polygon_sampling_bias","text":"","code":"# Load packages library(sf) library(dplyr) library(ggplot2)  # Set seed for reproducibility set.seed(123)  # Simulate some occurrence data with coordinates and time points num_points <- 10 occurrences <- data.frame(   lon = runif(num_points, min = -180, max = 180),   lat = runif(num_points, min = -90, max = 90),   time_point = 0   )  # Convert the occurrence data to an sf object occurrences_sf <- st_as_sf(occurrences, coords = c(\"lon\", \"lat\"))  # Create bias_area polygon overlapping at least two of the points selected_observations <- st_union(occurrences_sf[2:3,]) bias_area <- st_convex_hull(selected_observations) %>%   st_buffer(dist = 100) %>%   st_as_sf()  occurrence_bias_sf <- apply_polygon_sampling_bias(   occurrences_sf,   bias_area,   bias_strength = 2) occurrence_bias_sf #> Simple feature collection with 10 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #>    time_point                   geometry bias_weight #> 1           0    POINT (-76.47209 82.23)   0.6666667 #> 2           0 POINT (103.7898 -8.399852)   0.6666667 #> 3           0 POINT (-32.76831 31.96271)   0.6666667 #> 4           0  POINT (137.8863 13.07401)   0.6666667 #> 5           0 POINT (158.5682 -71.47356)   0.6666667 #> 6           0 POINT (-163.5997 71.96849)   0.3333333 #> 7           0 POINT (10.11798 -45.70421)   0.6666667 #> 8           0 POINT (141.2709 -82.42928)   0.6666667 #> 9           0 POINT (18.51661 -30.97427)   0.6666667 #> 10          0  POINT (-15.6187 81.81066)   0.6666667  # Visualise where the bias is occurrence_bias_sf %>%   mutate(bias_weight_f = as.factor(round(bias_weight, 3))) %>%   ggplot() +     geom_sf(data = bias_area) +     geom_sf(aes(colour = bias_weight_f)) +     ggtitle(\"Sampling Bias via Polygon\")"},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":null,"dir":"Reference","previous_headings":"","what":"Create spatial pattern within a polygon — create_spatial_pattern","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"creates raster spatial pattern area polygon.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"","code":"create_spatial_pattern(   polygon,   resolution,   spatial_pattern = c(\"random\", \"clustered\"),   seed = NA,   n_sim = 1 )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"polygon sf object geometry type POLYGON resolution numeric value defining resolution raster cell spatial_pattern Define spatial pattern. character string \"random\" \"clustered\", \"random\" default. user able provide numeric value >= 1 (1 \"random\" 10 \"clustered\"). larger number means broader size clusters area. See details. seed seed random number generation make results reproducible. NA (default), seed used. n_sim Number simulations. simulation different layer raster. Default 1.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"object class SpatRaster spatial pattern area given polygon.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"spatial_pattern argument change range parameter spherical variogram model. spatial_pattern = 1 means range size grid cell, defined resolution argument. use function gstat::vgm() implement spherical variogram model","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/create_spatial_pattern.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create spatial pattern within a polygon — create_spatial_pattern","text":"","code":"# Load packages library(sf) library(ggplot2) library(tidyterra) #>  #> Attaching package: ‘tidyterra’ #> The following object is masked from ‘package:stats’: #>  #>     filter  # Create polygon plgn <- st_polygon(list(cbind(c(5,10,8,2,3,5), c(2,1,7,9,5,2)))) ggplot() +   geom_sf(data = plgn) +   theme_minimal()   # Random spatial pattern rs_pattern_random <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = \"random\",   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_spatraster(data = rs_pattern_random) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()   ## Clustered spatial pattern rs_pattern_clustered <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = \"clustered\",   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_spatraster(data = rs_pattern_clustered) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()   ## User defined spatial pattern # Small scale clustering rs_pattern_small <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = 5,   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_spatraster(data = rs_pattern_small) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()   # Medium scale clustering (= the built-in clustered pattern) rs_pattern_medium <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = 10,   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_spatraster(data = rs_pattern_medium) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()   # Large scale clustering rs_pattern_large <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = 100,   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_spatraster(data = rs_pattern_large) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/reference/grid_designation.html","id":null,"dir":"Reference","previous_headings":"","what":"Observations to grid designation to create a data cube — grid_designation","title":"Observations to grid designation to create a data cube — grid_designation","text":"function designates observations cells given grid create aggregated data cube.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/grid_designation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Observations to grid designation to create a data cube — grid_designation","text":"","code":"grid_designation(   observations,   grid,   id_col = \"row_names\",   seed = NA,   aggregate = TRUE,   randomisation = c(\"uniform\", \"normal\"),   p_norm = ifelse(tolower(randomisation[1]) == \"uniform\", NA, 0.95) )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/grid_designation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Observations to grid designation to create a data cube — grid_designation","text":"observations sf object POINT geometry time_point coordinateUncertaintyInMeters column. last column present, function assume (zero meters) uncertainty around observation points. grid sf object POLYGON geometry (usually grid) observations designated. id_col column name column unique ids grid cell. \"row_names\" (default), new column id created row names represent unique ids. seed seed random number generation make results reproducible. NA (default), seed used. aggregate Logical. TRUE (default), return data cube aggregated form (grid number observations per grid cell). Otherwise return sampled points uncertainty circle. randomisation \"uniform\" \"normal\". Randomisation method used sampling within uncertainty circle around observation. default \"uniform\" means point uncertainty circle equal probability selected. option \"normal\" point sampled bivariate Normal distribution means equal observation point variance equal (-coordinateUncertaintyInMeters^2) / (2 * log(1 - p_norm)) p_norm % possible samples Normal distribution fall within uncertainty circle. p_norm numeric value 0 1. used randomisation = \"normal\". proportion possible samples bivariate Normal distribution fall within uncertainty circle. normal randomisation used value given, default p_norm value 0.95.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/grid_designation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Observations to grid designation to create a data cube — grid_designation","text":"case aggregate = TRUE, sf object POLYGON geometry containing locations grid cells, n column number observations per grid cell, min_coord_uncertainty column containing minimal coordinate uncertainty per grid cell. case aggregate = FALSE, sf object POINT geometry containing locations sampled observations within uncertainty circle, coordinateUncertaintyInMeters column containing coordinate uncertainty observation.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/grid_designation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Observations to grid designation to create a data cube — grid_designation","text":"","code":"library(sf) library(dplyr)  set.seed(123)  # Create four random points n_points <- 4 xlim <- c(3841000, 3842000) ylim <- c(3110000, 3112000) coordinate_uncertainty <- rgamma(n_points, shape = 5, rate = 0.1)  observations_sf <- data.frame(   lat = runif(n_points, ylim[1], ylim[2]),   long = runif(n_points, xlim[1], xlim[2]),   time_point = 1,   coordinateUncertaintyInMeters = coordinate_uncertainty ) %>%   st_as_sf(coords = c(\"long\", \"lat\"), crs = 3035)  # Add buffer uncertainty in meters around points observations_buffered <- observations_sf %>%   st_buffer(observations_sf$coordinateUncertaintyInMeters)  # Create grid grid_df <- st_make_grid(   observations_buffered,   square = TRUE,   cellsize = c(200, 200) ) %>%   st_sf()  # Create occurrence cube grid_designation(   observations = observations_sf,   grid = grid_df,   seed = 123 ) #> Simple feature collection with 30 features and 4 fields #> Geometry type: POLYGON #> Dimension:     XY #> Bounding box:  xmin: 3840994 ymin: 3110833 xmax: 3841994 ymax: 3112033 #> Projected CRS: ETRS89-extended / LAEA Europe #> # A tibble: 30 × 5 #>    time_point id        n min_coord_uncertainty                         geometry #>  *      <dbl> <chr> <int>                 <dbl>                    <POLYGON [m]> #>  1          1 12        1                  16.3 ((3841194 3111233, 3841394 3111… #>  2          1 26        1                  33.9 ((3840994 3111833, 3841194 3111… #>  3          1 5         1                  73.8 ((3841794 3110833, 3841994 3110… #>  4          1 6         1                  47.8 ((3840994 3111033, 3841194 3111… #>  5          1 1         0                  NA   ((3840994 3110833, 3841194 3110… #>  6          1 2         0                  NA   ((3841194 3110833, 3841394 3110… #>  7          1 3         0                  NA   ((3841394 3110833, 3841594 3110… #>  8          1 4         0                  NA   ((3841594 3110833, 3841794 3110… #>  9          1 7         0                  NA   ((3841194 3111033, 3841394 3111… #> 10          1 8         0                  NA   ((3841394 3111033, 3841594 3111… #> # ℹ 20 more rows"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_binormal_circle.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","title":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","text":"function samples occurrences species within uncertainty circle around observation assuming bivariate Normal distribution means equal observation point variance equal (-coordinateUncertaintyInMeters^2) / (2 * log(1 - p_norm)) p_norm % possible samples Normal distribution fall within uncertainty circle.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_binormal_circle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","text":"","code":"sample_from_binormal_circle(observations, p_norm = 0.95, seed = NA)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_binormal_circle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","text":"observations sf object POINT geometry time_point coordinateUncertaintyInMeters column. last column present, function assume (zero meters) uncertainty around observation points. p_norm numeric value 0 1. proportion possible samples bivariate Normal distribution fall within uncertainty circle. value given, default p_norm value 0.95. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_binormal_circle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","text":"sf object POINT geometry containing locations sampled occurrences coordinateUncertaintyInMeters column containing coordinate uncertainty observation.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_binormal_circle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a circle using the bivariate Normal distribution — sample_from_binormal_circle","text":"","code":"library(sf) library(dplyr)  set.seed(123)  # Create four random points n_points <- 4 xlim <- c(3841000, 3842000) ylim <- c(3110000, 3112000) coordinate_uncertainty <- rgamma(n_points, shape = 5, rate = 0.1)  observations_sf <- data.frame(   lat = runif(n_points, ylim[1], ylim[2]),   long = runif(n_points, xlim[1], xlim[2]),   time_point = 1,   coordinateUncertaintyInMeters = coordinate_uncertainty ) %>%   st_as_sf(coords = c(\"long\", \"lat\"), crs = 3035)  # Sample points within uncertainty circles according to normal rules sample_from_binormal_circle(   observations = observations_sf,   p_norm = 0.95,   seed = 123 ) #> Simple feature collection with 4 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 3841051 ymin: 3110909 xmax: 3841947 ymax: 3111911 #> Projected CRS: ETRS89-extended / LAEA Europe #>   time_point coordinateUncertaintyInMeters                geometry #> 1          1                      33.89585 POINT (3841095 3111911) #> 2          1                      73.78957 POINT (3841947 3110909) #> 3          1                      16.29561 POINT (3841247 3111367) #> 4          1                      47.78440 POINT (3841051 3111121)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_uniform_circle.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","title":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","text":"function samples occurrences species within uncertainty circle around observation assuming Uniform distribution.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_uniform_circle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","text":"","code":"sample_from_uniform_circle(observations, seed = NA)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_uniform_circle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","text":"observations sf object POINT geometry time_point coordinateUncertaintyInMeters column. last column present, function assume (zero meters) uncertainty around observation points. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_uniform_circle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","text":"sf object POINT geometry containing locations sampled occurrences coordinateUncertaintyInMeters column containing coordinate uncertainty observation.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_from_uniform_circle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample from a circle using the Uniform distribution — sample_from_uniform_circle","text":"","code":"library(sf)  set.seed(123)  # Create four random points n_points <- 4 xlim <- c(3841000, 3842000) ylim <- c(3110000, 3112000) coordinate_uncertainty <- rgamma(n_points, shape = 5, rate = 0.1)  observations_sf <- data.frame(   lat = runif(n_points, ylim[1], ylim[2]),   long = runif(n_points, xlim[1], xlim[2]),   time_point = 1,   coordinateUncertaintyInMeters = coordinate_uncertainty ) %>%   st_as_sf(coords = c(\"long\", \"lat\"), crs = 3035)  # Sample points within uncertainty circles according to uniform rules sample_from_uniform_circle(   observations = observations_sf,   seed = 123 ) #> Simple feature collection with 4 features and 2 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 3841076 ymin: 3110891 xmax: 3841904 ymax: 3111946 #> Projected CRS: ETRS89-extended / LAEA Europe #>   time_point coordinateUncertaintyInMeters                geometry #> 1          1                      33.89585 POINT (3841095 3111946) #> 2          1                      73.78957 POINT (3841904 3110891) #> 3          1                      16.29561 POINT (3841236 3111362) #> 4          1                      47.78440 POINT (3841076 3111115)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_observations.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample observations from a larger occurrence dataset — sample_observations","title":"Sample observations from a larger occurrence dataset — sample_observations","text":"function samples observations occurrences based detection probability sampling bias implementing Bernoulli trial.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_observations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample observations from a larger occurrence dataset — sample_observations","text":"","code":"sample_observations(   occurrences,   detection_probability = 1,   sampling_bias = c(\"no_bias\", \"polygon\", \"manual\"),   bias_area = NA,   bias_strength = 1,   bias_weights = NA,   seed = NA )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_observations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample observations from a larger occurrence dataset — sample_observations","text":"occurrences sf object POINT geometry. detection_probability numeric value 0 1, corresponding probability detection species. sampling_bias \"no_bias\", \"polygon\" \"manual\". method used generate sampling bias. \"polygon\": bias sampling polygon. Provide polygon bias_area. Provide bias strength bias_strength. \"manual\": bias sampling manually via raster. Provide raster layer cell contains probability sampled bias_weights. bias_area NA sf object POLYGON geometry. used sampling_bias = \"polygon\". area sampling biased. bias_strength NA positive numeric value. used sampling_bias = \"polygon\". strength bias applied biased area (multiplier). 1, area oversampled. 1, area undersampled. example, value 50 result 50 times sampling probability within bias_area outside. Conversely, value 0.5 result half less samples within bias_area outside. bias_weights NA raster layer (sf object POLYGON geometry). used sampling_bias = \"manual\". raster bias weights applied sampling occurrences. Higher weights mean higher probability sampling. Weights can numeric values 0 1 positive integers rescaled values 0 1. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_observations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample observations from a larger occurrence dataset — sample_observations","text":"sf object POINT geometry containing locations sampled observations, detection_probability column containing detection probability observation (), bias_weight column containing sampling probability based sampling bias, sampling_probability column containing combined sampling probability detection probability sampling bias observation, sampling_status column indicating whether occurrence detected (observations) (unobserved occurrences).","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_observations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample observations from a larger occurrence dataset — sample_observations","text":"","code":"# Load packages library(sf) library(dplyr)  # Set seed for reproducibility set.seed(123)  # Simulate some occurrence data with coordinates and time points num_points <- 10 occurrences <- data.frame(   lon = runif(num_points, min = -180, max = 180),   lat = runif(num_points, min = -90, max = 90),   time_point = 0   )  # Convert the occurrence data to an sf object occurrences_sf <- st_as_sf(occurrences, coords = c(\"lon\", \"lat\"))  # Sample observations without sampling bias sample_observations(   occurrences_sf,   detection_probability = 0.8,   sampling_bias = \"no_bias\",   seed = 123   ) #> Simple feature collection with 10 features and 5 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #> # A tibble: 10 × 6 #>    time_point detection_probability bias_weight sampling_probability #>         <dbl>                 <dbl>       <dbl>                <dbl> #>  1          0                   0.8           1                  0.8 #>  2          0                   0.8           1                  0.8 #>  3          0                   0.8           1                  0.8 #>  4          0                   0.8           1                  0.8 #>  5          0                   0.8           1                  0.8 #>  6          0                   0.8           1                  0.8 #>  7          0                   0.8           1                  0.8 #>  8          0                   0.8           1                  0.8 #>  9          0                   0.8           1                  0.8 #> 10          0                   0.8           1                  0.8 #> # ℹ 2 more variables: sampling_status <chr>, geometry <POINT>  # Sample observations with sampling bias in a polygon # Create bias_area polygon overlapping two of the points selected_observations <- st_union(occurrences_sf[2:3,]) bias_area <- st_convex_hull(selected_observations) %>%   st_buffer(dist = 100) %>%   st_as_sf()  sample_observations(   occurrences_sf,   detection_probability = 0.8,   sampling_bias = \"polygon\",   bias_area = bias_area,   bias_strength = 2,   seed = 123   ) #> Simple feature collection with 10 features and 5 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #> # A tibble: 10 × 6 #>    time_point detection_probability bias_weight sampling_probability #>         <dbl>                 <dbl>       <dbl>                <dbl> #>  1          0                   0.8       0.667                0.533 #>  2          0                   0.8       0.667                0.533 #>  3          0                   0.8       0.667                0.533 #>  4          0                   0.8       0.667                0.533 #>  5          0                   0.8       0.667                0.533 #>  6          0                   0.8       0.333                0.267 #>  7          0                   0.8       0.667                0.533 #>  8          0                   0.8       0.667                0.533 #>  9          0                   0.8       0.667                0.533 #> 10          0                   0.8       0.667                0.533 #> # ℹ 2 more variables: sampling_status <chr>, geometry <POINT>  # Sample observations with sampling bias given manually in a grid # Create raster grid with bias weights between 0 and 1 grid <- st_make_grid(occurrences_sf) %>%   st_sf() %>%   mutate(bias_weight = runif(n(), min = 0, max = 1))  sample_observations(   occurrences_sf,   detection_probability = 0.8,   sampling_bias = \"manual\",   bias_weights = grid,   seed = 123   ) #> Simple feature collection with 10 features and 5 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: -163.5997 ymin: -82.42928 xmax: 158.5682 ymax: 82.23 #> CRS:           NA #> # A tibble: 10 × 6 #>    time_point detection_probability bias_weight sampling_probability #>         <dbl>                 <dbl>       <dbl>                <dbl> #>  1          0                   0.8       0.955                0.764 #>  2          0                   0.8       0.955                0.764 #>  3          0                   0.8       0.478                0.382 #>  4          0                   0.8       0.139                0.111 #>  5          0                   0.8       0.895                0.716 #>  6          0                   0.8       0.440                0.352 #>  7          0                   0.8       0.475                0.380 #>  8          0                   0.8       0.600                0.480 #>  9          0                   0.8       0.489                0.391 #> 10          0                   0.8       0.483                0.386 #> # ℹ 2 more variables: sampling_status <chr>, geometry <POINT>"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_occurrences_from_raster.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample occurrences from spatial random field — sample_occurrences_from_raster","title":"Sample occurrences from spatial random field — sample_occurrences_from_raster","text":"Draws occurrences (points) spatial random field (raster)","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_occurrences_from_raster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample occurrences from spatial random field — sample_occurrences_from_raster","text":"","code":"sample_occurrences_from_raster(rs, ts, seed = NA)"},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_occurrences_from_raster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample occurrences from spatial random field — sample_occurrences_from_raster","text":"rs raster object (terra). ts vector number occurrences per time point. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_occurrences_from_raster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample occurrences from spatial random field — sample_occurrences_from_raster","text":"sf object POINT geometry","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/sample_occurrences_from_raster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample occurrences from spatial random field — sample_occurrences_from_raster","text":"","code":"# Load packages library(sf) library(ggplot2) library(tidyterra)  # Create polygon plgn <- st_polygon(list(cbind(c(5,10,8,2,3,5), c(2,1,7,9,5,2)))) ggplot() +   geom_sf(data = plgn) +   theme_minimal()   ## Medium scale clustering # Create the random field rs_pattern_clustered <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = \"clustered\",   seed = 123) #> [using unconditional Gaussian simulation]  # Sample 200 occurrences from random field pts_occ_clustered <- sample_occurrences_from_raster(   rs = rs_pattern_clustered,   ts = 200,   seed = 123)  ggplot() +   geom_spatraster(data = rs_pattern_clustered) +   geom_sf(data = pts_occ_clustered) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()   ## Large scale clustering # Create the random field rs_pattern_large <- create_spatial_pattern(   polygon = plgn,   resolution = 0.1,   spatial_pattern = 100,   seed = 123) #> [using unconditional Gaussian simulation]  # Sample 200 occurrences from random field pts_occ_large <- sample_occurrences_from_raster(   rs = rs_pattern_large,   ts = 200,   seed = 123)  ggplot() +   geom_spatraster(data = rs_pattern_large) +   geom_sf(data = pts_occ_large) +   scale_fill_continuous(type = \"viridis\") +   theme_minimal()"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_occurrences.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","title":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","text":"function simulates occurrences species within given spatial /temporal extend.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_occurrences.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","text":"","code":"simulate_occurrences(   plgn,   initial_average_abundance = 50,   spatial_autocorr = c(\"random\", \"clustered\"),   n_time_points = 1,   temporal_function = NA,   ...,   seed = NA )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_occurrences.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","text":"plgn sf object POLYGON geometry indicating spatial extend simulate occurrences. initial_average_abundance positive integer value indicating average number occurrences simulated within extend polygon time point 1. value used mean Poisson distribution (lambda parameter). spatial_autocorr Define spatial pattern. character string \"random\" \"clustered\", \"random\" default. user able provide numeric value >= 1 (1 \"random\" 10 \"clustered\"). larger number means broader size clusters area. See details. n_time_points positive integer value indicating number time points simulate. temporal_function NA (default), function generates trend abundance time. used n_time_points > 1. default, function sample n_time_points times Poisson distribution average (lambda) initial_average_occurrences. function specified (e.g. internal simulate_random_walk() function). ... Additional argument passed temporal_function function. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_occurrences.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","text":"sf object POINT geometry containing locations simulated occurrences time_point column containing time point associated occurrence.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_occurrences.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate occurrences within a spatiotemporal scope — simulate_occurrences","text":"","code":"# Load packages library(sf) library(ggplot2)  # Create polygon plgn <- st_polygon(list(cbind(c(5,10,8,2,3,5), c(2,1,7,9,5,2)))) ggplot() +   geom_sf(data = plgn) +   theme_minimal()   ## Random spatial pattern with 4 time points occ_sf <- simulate_occurrences(   plgn,   n_time_points = 4,   initial_average_abundance = 100,   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +  geom_sf(data = occ_sf) +  geom_sf(data = plgn, fill = NA) +  facet_wrap(\"time_point\") +  labs(       title = \"Occurrences with random\\nspatial and temporal pattern\",       subtitle = \"4 time steps\") +  theme_bw()   ## Clustered spatial pattern with 4 time points occ_sf_100 <- simulate_occurrences(   plgn,   spatial_autocorr = 100,   n_time_points = 4,   initial_average_abundance = 100,   seed = 123) #> [using unconditional Gaussian simulation]  ggplot() +   geom_sf(data = occ_sf_100) +   geom_sf(data = plgn, fill = NA) +   facet_wrap(\"time_point\") +   labs(        title = \"Occurrences with structured\\nspatial and temporal pattern\",        subtitle = \"4 time steps\") +   theme_bw()"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_random_walk.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a random walk over time — simulate_random_walk","title":"Simulate a random walk over time — simulate_random_walk","text":"function simulates occurrences species temporal extent.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_random_walk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a random walk over time — simulate_random_walk","text":"","code":"simulate_random_walk(   initial_average_occurrences = 50,   n_time_points = 10,   sd_step = 0.05,   seed = NA )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_random_walk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a random walk over time — simulate_random_walk","text":"initial_average_occurrences positive integer value indicating average number occurrences simulated within extend polygon time point 1. value used mean Poisson distribution (lambda parameter). n_time_points positive integer value indicating number time points simulate. sd_step positive numeric value indicating standard deviation random steps. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_random_walk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a random walk over time — simulate_random_walk","text":"vector integers length n_time_points average number occurrences.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_random_walk.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a random walk over time — simulate_random_walk","text":"","code":"simulate_random_walk(   initial_average_occurrences = 50,   n_time_points = 10,   sd_step = 1,   seed = 123 ) #>  [1] 50.00000 49.43952 49.20935 50.76806 50.83856 50.96785 52.68292 53.14383 #>  [9] 51.87877 51.19192"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate timeseries for species abundances — simulate_timeseries","title":"Simulate timeseries for species abundances — simulate_timeseries","text":"function simulates timeseries abundance species.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate timeseries for species abundances — simulate_timeseries","text":"","code":"simulate_timeseries(   initial_average_occurrences = 50,   n_time_points = 1,   temporal_function = NA,   ...,   seed = NA )"},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_timeseries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate timeseries for species abundances — simulate_timeseries","text":"initial_average_occurrences positive integer value indicating average number occurrences simulated within extend polygon first time point. value used mean Poisson distribution (lambda parameter). n_time_points positive integer value indicating number time points simulate. temporal_function NA (default), function generates trend abundance time. used n_time_points > 1. default, function sample n_time_points times Poisson distribution average (lambda) initial_average_occurrences. function specified (e.g. internal simulate_random_walk() function) n_time_points average abundances (lambdas) calculated using initial_average_occurrences additional arguments passed. See examples. ... Additional argument passed temporal_function function. seed positive numeric value. seed random number generation make results reproducible. NA (default), seed used.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_timeseries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate timeseries for species abundances — simulate_timeseries","text":"vector integers length n_time_points number occurrences.","code":""},{"path":[]},{"path":"https://b-cubed-eu.github.io/gcube/reference/simulate_timeseries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate timeseries for species abundances — simulate_timeseries","text":"","code":"library(ggplot2)  ## 1. Use the function simulate_random_walk() simulate_timeseries(   initial_average_occurrences = 50,   n_time_points = 10,   temporal_function = simulate_random_walk,   sd_step = 1,   seed = 123 ) #>  [1] 46 52 66 54 52 43 56 38 46 43  ## 2. Visualising multiple draws # Set seed for reproducibility set.seed(123)  # Draw n_sim abundances from Poisson distribution using random walk n_sim <- 10 n_time_points <- 50 sd_step <- 1 list_abundances <- vector(\"list\", length = n_sim)  # Loop n_sim times over simulate_timeseries() for (i in seq_len(n_sim)) {   abundances <- simulate_timeseries(     initial_average_occurrences = 50,     n_time_points = n_time_points,     temporal_function = simulate_random_walk,     sd_step = sd_step   )    list_abundances[[i]] <- data.frame(     time = seq_along(abundances),     abundance = abundances,     sim = i   ) }  # Combine list of dataframes data_abundances <- do.call(rbind.data.frame, list_abundances)  # Plot the simulated abundances over time using ggplot2 ggplot(data_abundances, aes(x = time, y = abundance, colour = factor(sim))) +   geom_line() +   labs(     x = \"Time\", y = \"Species abundance\",     title = paste(       n_sim, \"simulated abundances using random walk\",       \"with sd =\", sd_step     )   ) +   scale_y_continuous(limits = c(0, NA)) +   scale_x_continuous(breaks = seq(0, n_time_points, 5)) +   theme_minimal() +   theme(legend.position = \"\")   ## 3. Using your own function # You can also specify your own trend function, e.g. this linear function my_own_linear_function <- function(     initial_average_occurrences = initial_average_occurrences,     n_time_points = n_time_points,     coef) {   # Calculate new average abundances over time   time <- seq_len(n_time_points) - 1   lambdas <- initial_average_occurrences + (coef * time)    # Identify where the lambda values become 0 or lower   zero_or_lower_index <- which(lambdas <= 0)    # If any lambda becomes 0 or lower, set all subsequent lambdas to 0   if (length(zero_or_lower_index) > 0) {     zero_or_lower_indices <- zero_or_lower_index[1]:n_time_points     lambdas[zero_or_lower_indices] <- 0   }    # Return average abundances   return(lambdas) }  # Set seed for reproducibility set.seed(123)  # Draw n_sim abundances from Poisson distribution using our own function n_sim <- 10 n_time_points <- 50 slope <- 1 list_abundances <- vector(\"list\", length = n_sim)  # Loop n_sim times over simulate_timeseries() for (i in seq_len(n_sim)) {   abundances <- simulate_timeseries(     initial_average_occurrences = 50,     n_time_points = n_time_points,     temporal_function = my_own_linear_function,     coef = slope   )    list_abundances[[i]] <- data.frame(     time = seq_along(abundances),     abundance = abundances,     sim = i   ) }  # Combine list of dataframes data_abundances <- do.call(rbind.data.frame, list_abundances)  # Plot the simulated abundances over time using ggplot2 ggplot(data_abundances, aes(x = time, y = abundance, colour = factor(sim))) +   geom_line() +   labs(     x = \"Time\", y = \"Species abundance\",     title = paste(       n_sim, \"simulated abundances using our own linear function\",       \"with slope\", slope     )   ) +   scale_y_continuous(limits = c(0, NA)) +   scale_x_continuous(breaks = seq(0, n_time_points, 5)) +   theme_minimal() +   theme(legend.position = \"\")"},{"path":"https://b-cubed-eu.github.io/gcube/news/index.html","id":"gcube-001","dir":"Changelog","previous_headings":"","what":"gcube 0.0.1","title":"gcube 0.0.1","text":"Add checklist infrastructure.","code":""},{"path":"https://b-cubed-eu.github.io/gcube/news/index.html","id":"gcube-000","dir":"Changelog","previous_headings":"","what":"gcube 0.0.0","title":"gcube 0.0.0","text":"Added NEWS.md file track changes package.","code":""}]
